{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例重點\n",
    "### 學習在模型開始前檢查各個環節\n",
    "1. 是否有 GPU 資源\n",
    "2. 將前處理轉為函式，統一處理訓練、驗證與測試集\n",
    "3. 將超參數變數化，易於重複使用函式、模型等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: nvidia-smi: command not found\r\n"
     ]
    }
   ],
   "source": [
    "## 確認硬體資源 (如果你是在 Linux, 若是在 Windows, 請參考 https://blog.csdn.net/idwtwt/article/details/78017565)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# 本範例不需使用 GPU, 將 GPU 設定為 \"無\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從 Keras 的內建功能中，取得 train 與 test 資料集\n",
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "        \n",
    "    x=2*(x-x.min())/(x.max()-x.min())-1\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# 資料前處理 - X 標準化\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# 資料前處理 -Y 轉成 onehot\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128, 64, 32]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0723 14:22:08.727488 4698977728 deprecation_wrapper.py:119] From /Users/vincent/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0723 14:22:08.749393 4698977728 deprecation_wrapper.py:119] From /Users/vincent/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0723 14:22:08.753394 4698977728 deprecation_wrapper.py:119] From /Users/vincent/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 1,748,266\n",
      "Trainable params: 1,748,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_mlp(input_shape=x_train.shape[1:])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0723 14:22:13.450048 4698977728 deprecation_wrapper.py:119] From /Users/vincent/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0723 14:22:13.461839 4698977728 deprecation_wrapper.py:119] From /Users/vincent/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=LEARNING_RATE)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0723 14:22:14.791799 4698977728 deprecation.py:323] From /Users/vincent/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0723 14:22:15.064532 4698977728 deprecation_wrapper.py:119] From /Users/vincent/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 1.7263 - acc: 0.3865 - val_loss: 1.5589 - val_acc: 0.4430\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 1.4849 - acc: 0.4758 - val_loss: 1.4799 - val_acc: 0.4801\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 1.3688 - acc: 0.5178 - val_loss: 1.4025 - val_acc: 0.5002\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 1.2743 - acc: 0.5501 - val_loss: 1.3863 - val_acc: 0.5096\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 1.1851 - acc: 0.5855 - val_loss: 1.3488 - val_acc: 0.5307\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 1.1111 - acc: 0.6085 - val_loss: 1.3912 - val_acc: 0.5181\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 1.0418 - acc: 0.6346 - val_loss: 1.3576 - val_acc: 0.5392\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.9685 - acc: 0.6574 - val_loss: 1.3918 - val_acc: 0.5353\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.9028 - acc: 0.6808 - val_loss: 1.4482 - val_acc: 0.5257\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.8340 - acc: 0.7036 - val_loss: 1.4429 - val_acc: 0.5437\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.7627 - acc: 0.7295 - val_loss: 1.5576 - val_acc: 0.5370\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.7124 - acc: 0.7501 - val_loss: 1.5408 - val_acc: 0.5351\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.6524 - acc: 0.7706 - val_loss: 1.6508 - val_acc: 0.5338\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.6023 - acc: 0.7864 - val_loss: 1.6588 - val_acc: 0.5422\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.5479 - acc: 0.8059 - val_loss: 1.7447 - val_acc: 0.5419\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.5014 - acc: 0.8233 - val_loss: 1.8566 - val_acc: 0.5294\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.4534 - acc: 0.8392 - val_loss: 2.0159 - val_acc: 0.5273\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.4287 - acc: 0.8508 - val_loss: 2.0102 - val_acc: 0.5283\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.3847 - acc: 0.8650 - val_loss: 2.0999 - val_acc: 0.5312\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.3617 - acc: 0.8741 - val_loss: 2.1736 - val_acc: 0.5322\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.3346 - acc: 0.8834 - val_loss: 2.2127 - val_acc: 0.5339\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.3097 - acc: 0.8912 - val_loss: 2.3763 - val_acc: 0.5349\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.2921 - acc: 0.8984 - val_loss: 2.5090 - val_acc: 0.5244\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.2724 - acc: 0.9043 - val_loss: 2.5799 - val_acc: 0.5242\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.2632 - acc: 0.9080 - val_loss: 2.6517 - val_acc: 0.5257\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.2429 - acc: 0.9153 - val_loss: 2.6944 - val_acc: 0.5254\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.2391 - acc: 0.9169 - val_loss: 2.7263 - val_acc: 0.5286\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.2087 - acc: 0.9281 - val_loss: 2.7346 - val_acc: 0.5324\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.2028 - acc: 0.9312 - val_loss: 2.9765 - val_acc: 0.5223\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.2056 - acc: 0.9294 - val_loss: 2.8915 - val_acc: 0.5286\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.2192 - acc: 0.9246 - val_loss: 2.8338 - val_acc: 0.5220\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.1784 - acc: 0.9383 - val_loss: 3.0082 - val_acc: 0.5294\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.1714 - acc: 0.9396 - val_loss: 3.0755 - val_acc: 0.5222\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.1938 - acc: 0.9334 - val_loss: 3.0967 - val_acc: 0.5210\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1708 - acc: 0.9419 - val_loss: 3.1488 - val_acc: 0.5236\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.1467 - acc: 0.9498 - val_loss: 3.2287 - val_acc: 0.5248\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.1545 - acc: 0.9471 - val_loss: 3.2427 - val_acc: 0.5333\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.1654 - acc: 0.9444 - val_loss: 3.1993 - val_acc: 0.5248\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.1592 - acc: 0.9467 - val_loss: 3.2866 - val_acc: 0.5262\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.1421 - acc: 0.9493 - val_loss: 3.3596 - val_acc: 0.5203\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.1410 - acc: 0.9525 - val_loss: 3.3194 - val_acc: 0.5203\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.1446 - acc: 0.9510 - val_loss: 3.3367 - val_acc: 0.5283\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.1288 - acc: 0.9572 - val_loss: 3.3719 - val_acc: 0.5342\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.1407 - acc: 0.9528 - val_loss: 3.3621 - val_acc: 0.5227\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.1423 - acc: 0.9525 - val_loss: 3.4412 - val_acc: 0.5340\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.1388 - acc: 0.9549 - val_loss: 3.4337 - val_acc: 0.5234\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.1302 - acc: 0.9551 - val_loss: 3.3822 - val_acc: 0.5312\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.0990 - acc: 0.9663 - val_loss: 3.6535 - val_acc: 0.5296\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.1141 - acc: 0.9612 - val_loss: 3.6042 - val_acc: 0.5354\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.1408 - acc: 0.9536 - val_loss: 3.5640 - val_acc: 0.5354\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.1145 - acc: 0.9608 - val_loss: 3.6183 - val_acc: 0.5345\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.1012 - acc: 0.9661 - val_loss: 3.6650 - val_acc: 0.5202\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.1127 - acc: 0.9628 - val_loss: 3.6229 - val_acc: 0.5286\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.1047 - acc: 0.9656 - val_loss: 3.5473 - val_acc: 0.5345\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.1213 - acc: 0.9598 - val_loss: 3.6737 - val_acc: 0.5291\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.1268 - acc: 0.9573 - val_loss: 3.6700 - val_acc: 0.5214\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.0997 - acc: 0.9654 - val_loss: 3.6641 - val_acc: 0.5335\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.0967 - acc: 0.9683 - val_loss: 3.7300 - val_acc: 0.5324\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.1139 - acc: 0.9626 - val_loss: 3.6140 - val_acc: 0.5300\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 0.1092 - acc: 0.9643 - val_loss: 3.6439 - val_acc: 0.5305\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.1033 - acc: 0.9663 - val_loss: 3.6784 - val_acc: 0.5326\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.0913 - acc: 0.9705 - val_loss: 3.6621 - val_acc: 0.5329\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.0795 - acc: 0.9743 - val_loss: 3.7266 - val_acc: 0.5326\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.1148 - acc: 0.9630 - val_loss: 3.7865 - val_acc: 0.5245\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.0855 - acc: 0.9710 - val_loss: 3.8096 - val_acc: 0.5284\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.0853 - acc: 0.9723 - val_loss: 3.7931 - val_acc: 0.5295\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.1241 - acc: 0.9598 - val_loss: 3.7271 - val_acc: 0.5302\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 0.0924 - acc: 0.9698 - val_loss: 3.7607 - val_acc: 0.5291\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.0842 - acc: 0.9728 - val_loss: 3.8481 - val_acc: 0.5309\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.0826 - acc: 0.9733 - val_loss: 3.8467 - val_acc: 0.5219\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 0.1034 - acc: 0.9660 - val_loss: 3.7782 - val_acc: 0.5320\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.0844 - acc: 0.9719 - val_loss: 3.8940 - val_acc: 0.5261\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.0871 - acc: 0.9718 - val_loss: 3.8542 - val_acc: 0.5234\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.0776 - acc: 0.9741 - val_loss: 3.8366 - val_acc: 0.5311\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.0789 - acc: 0.9753 - val_loss: 3.8239 - val_acc: 0.5264\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.0726 - acc: 0.9762 - val_loss: 3.8869 - val_acc: 0.5337\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.1039 - acc: 0.9670 - val_loss: 3.7653 - val_acc: 0.5211\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.0912 - acc: 0.9708 - val_loss: 3.8035 - val_acc: 0.5280\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.0828 - acc: 0.9740 - val_loss: 3.8896 - val_acc: 0.5226\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.0740 - acc: 0.9757 - val_loss: 3.9848 - val_acc: 0.5363\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.0885 - acc: 0.9717 - val_loss: 3.8898 - val_acc: 0.5275\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.0739 - acc: 0.9759 - val_loss: 3.9117 - val_acc: 0.5312\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.0640 - acc: 0.9796 - val_loss: 3.9468 - val_acc: 0.5328\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.0817 - acc: 0.9738 - val_loss: 3.8665 - val_acc: 0.5302\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.0894 - acc: 0.9717 - val_loss: 3.7955 - val_acc: 0.5316\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 0.0848 - acc: 0.9734 - val_loss: 3.9249 - val_acc: 0.5306\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 0.0702 - acc: 0.9776 - val_loss: 3.9821 - val_acc: 0.5306\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.0609 - acc: 0.9802 - val_loss: 4.0505 - val_acc: 0.5255\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.0641 - acc: 0.9792 - val_loss: 4.0243 - val_acc: 0.5252\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.0819 - acc: 0.9741 - val_loss: 3.9135 - val_acc: 0.5291\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.0786 - acc: 0.9752 - val_loss: 3.9574 - val_acc: 0.5271\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.0704 - acc: 0.9765 - val_loss: 4.0166 - val_acc: 0.5344\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.0630 - acc: 0.9806 - val_loss: 4.0231 - val_acc: 0.5277\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.0614 - acc: 0.9807 - val_loss: 4.0199 - val_acc: 0.5267\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.0823 - acc: 0.9738 - val_loss: 4.0231 - val_acc: 0.5315\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.0556 - acc: 0.9821 - val_loss: 4.0096 - val_acc: 0.5266\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.0856 - acc: 0.9730 - val_loss: 4.0300 - val_acc: 0.5306\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.0783 - acc: 0.9757 - val_loss: 3.8636 - val_acc: 0.5290\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.0696 - acc: 0.9781 - val_loss: 3.9350 - val_acc: 0.5366\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.0532 - acc: 0.9831 - val_loss: 4.0264 - val_acc: 0.5382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb961bb7f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 訓練模型並檢視驗證集的結果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
    "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
    "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請嘗試將 preproc_x 替換成以每筆資料的 min/max 進行標準化至 -1 ~ 1 間，再進行訓練\n",
    "2. 請嘗試將 mlp 疊更深 (e.g 5~10 層)，進行訓練後觀察 learning curve 的走勢\n",
    "3. (optional) 請改用 GPU 進行訓練 (如果你有 GPU 的話)，比較使用 CPU 與 GPU 的訓練速度"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
