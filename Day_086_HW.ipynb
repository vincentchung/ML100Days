{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "* 試比較 save_best_only 與否的差異\n",
    "* 請僅存入將 save_weights_only 設定為 True,\n",
    "* 並嘗試 reset ipynb 並將模型與權重重新建回並預測 x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# 本範例不需使用 GPU, 將 GPU 設定為 \"無\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# 資料前處理 - X 標準化\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# 資料前處理 -Y 轉成 onehot\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "\"\"\"\n",
    "建立神經網路，並加入 BN layer\n",
    "\"\"\"\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "            x = BatchNormalization()(x)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 1024\n",
    "MOMENTUM = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 載入 Callbacks, 並將監控目標設為 validation loss, 且只存最佳參數時的模型\n",
    "\"\"\"\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_ckpt = ModelCheckpoint(filepath=\"./tmp.h5\", \n",
    "                             monitor=\"val_loss\", \n",
    "                             save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.1954 - acc: 0.2745 - val_loss: 2.0516 - val_acc: 0.3291\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 4s 74us/step - loss: 1.7474 - acc: 0.3958 - val_loss: 1.7855 - val_acc: 0.3869\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.6211 - acc: 0.4325 - val_loss: 1.6874 - val_acc: 0.4144\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5485 - acc: 0.4606 - val_loss: 1.6319 - val_acc: 0.4290\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.4936 - acc: 0.4784 - val_loss: 1.5957 - val_acc: 0.4412\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.4482 - acc: 0.4954 - val_loss: 1.5729 - val_acc: 0.4460\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.4070 - acc: 0.5101 - val_loss: 1.5506 - val_acc: 0.4539\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.3723 - acc: 0.5231 - val_loss: 1.5377 - val_acc: 0.4511\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.3383 - acc: 0.5348 - val_loss: 1.5134 - val_acc: 0.4621\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.3090 - acc: 0.5449 - val_loss: 1.5137 - val_acc: 0.4597\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2814 - acc: 0.5568 - val_loss: 1.5047 - val_acc: 0.4655\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.2531 - acc: 0.5665 - val_loss: 1.5109 - val_acc: 0.4708\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.2265 - acc: 0.5753 - val_loss: 1.4930 - val_acc: 0.4706\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 1.2010 - acc: 0.5850 - val_loss: 1.4706 - val_acc: 0.4799\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.1784 - acc: 0.5930 - val_loss: 1.4838 - val_acc: 0.4788\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.1538 - acc: 0.6046 - val_loss: 1.4715 - val_acc: 0.4789\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.1290 - acc: 0.6133 - val_loss: 1.4641 - val_acc: 0.4886\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.1081 - acc: 0.6209 - val_loss: 1.4670 - val_acc: 0.4832\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.0856 - acc: 0.6298 - val_loss: 1.4651 - val_acc: 0.4869\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.0628 - acc: 0.6385 - val_loss: 1.4650 - val_acc: 0.4877\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.0407 - acc: 0.6472 - val_loss: 1.4585 - val_acc: 0.4910\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.0195 - acc: 0.6569 - val_loss: 1.4636 - val_acc: 0.4873\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.9983 - acc: 0.6630 - val_loss: 1.4676 - val_acc: 0.4858\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.9790 - acc: 0.6721 - val_loss: 1.4569 - val_acc: 0.4949\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.9567 - acc: 0.6789 - val_loss: 1.4716 - val_acc: 0.4887\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 0.9373 - acc: 0.6868 - val_loss: 1.4768 - val_acc: 0.4878\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.9167 - acc: 0.6933 - val_loss: 1.4881 - val_acc: 0.4889\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.8973 - acc: 0.7032 - val_loss: 1.4846 - val_acc: 0.4934\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.8775 - acc: 0.7103 - val_loss: 1.4895 - val_acc: 0.4895\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 0.8574 - acc: 0.7177 - val_loss: 1.4884 - val_acc: 0.4885\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.8392 - acc: 0.7264 - val_loss: 1.4994 - val_acc: 0.4893\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.8165 - acc: 0.7336 - val_loss: 1.5012 - val_acc: 0.4950\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.7973 - acc: 0.7416 - val_loss: 1.5162 - val_acc: 0.4861\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.7786 - acc: 0.7490 - val_loss: 1.5155 - val_acc: 0.4913\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 0.7578 - acc: 0.7573 - val_loss: 1.5371 - val_acc: 0.4901\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.7408 - acc: 0.7646 - val_loss: 1.5406 - val_acc: 0.4909\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.7215 - acc: 0.7720 - val_loss: 1.5560 - val_acc: 0.4875\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 0.7026 - acc: 0.7787 - val_loss: 1.5620 - val_acc: 0.4925\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.6850 - acc: 0.7860 - val_loss: 1.5746 - val_acc: 0.4892\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.6663 - acc: 0.7953 - val_loss: 1.5798 - val_acc: 0.4903\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.6474 - acc: 0.8032 - val_loss: 1.5869 - val_acc: 0.4907\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.6293 - acc: 0.8088 - val_loss: 1.5955 - val_acc: 0.4912\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.6107 - acc: 0.8177 - val_loss: 1.6117 - val_acc: 0.4879\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.5935 - acc: 0.8226 - val_loss: 1.6363 - val_acc: 0.4825\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 0.5755 - acc: 0.8302 - val_loss: 1.6247 - val_acc: 0.4911\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.5583 - acc: 0.8369 - val_loss: 1.6364 - val_acc: 0.4889\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.5402 - acc: 0.8431 - val_loss: 1.6552 - val_acc: 0.4824\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.5219 - acc: 0.8500 - val_loss: 1.6779 - val_acc: 0.4811\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.5082 - acc: 0.8563 - val_loss: 1.6809 - val_acc: 0.4913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.4912 - acc: 0.8632 - val_loss: 1.6901 - val_acc: 0.4796\n",
      "10000/10000 [==============================] - 1s 104us/step\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.0562 - acc: 0.6393 - val_loss: 1.4506 - val_acc: 0.4885\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.0368 - acc: 0.6460 - val_loss: 1.4681 - val_acc: 0.4865\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.0158 - acc: 0.6547 - val_loss: 1.4623 - val_acc: 0.4865\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.9935 - acc: 0.6627 - val_loss: 1.4571 - val_acc: 0.4903\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.9712 - acc: 0.6725 - val_loss: 1.4600 - val_acc: 0.4936\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.9531 - acc: 0.6793 - val_loss: 1.4539 - val_acc: 0.4970\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.9329 - acc: 0.6867 - val_loss: 1.4685 - val_acc: 0.4899\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.9119 - acc: 0.6951 - val_loss: 1.4676 - val_acc: 0.4978\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.8920 - acc: 0.7041 - val_loss: 1.4543 - val_acc: 0.4949\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.8717 - acc: 0.7102 - val_loss: 1.4659 - val_acc: 0.4994\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.8512 - acc: 0.7182 - val_loss: 1.4725 - val_acc: 0.4965\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.8331 - acc: 0.7265 - val_loss: 1.4956 - val_acc: 0.4860\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.8134 - acc: 0.7333 - val_loss: 1.5012 - val_acc: 0.4967\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 0.7940 - acc: 0.7416 - val_loss: 1.5098 - val_acc: 0.4930\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.7756 - acc: 0.7480 - val_loss: 1.5025 - val_acc: 0.4935\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.7560 - acc: 0.7575 - val_loss: 1.5108 - val_acc: 0.4924\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 0.7368 - acc: 0.7638 - val_loss: 1.5364 - val_acc: 0.4878\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.7169 - acc: 0.7723 - val_loss: 1.5362 - val_acc: 0.4957\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 0.6986 - acc: 0.7809 - val_loss: 1.5294 - val_acc: 0.4955\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.6809 - acc: 0.7867 - val_loss: 1.5501 - val_acc: 0.4927\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 0.6633 - acc: 0.7940 - val_loss: 1.5541 - val_acc: 0.4955\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 0.6428 - acc: 0.8011 - val_loss: 1.5774 - val_acc: 0.4910\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.6249 - acc: 0.8091 - val_loss: 1.5906 - val_acc: 0.4884\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 0.6109 - acc: 0.8136 - val_loss: 1.5915 - val_acc: 0.4886\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.5922 - acc: 0.8216 - val_loss: 1.5891 - val_acc: 0.4914\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.5735 - acc: 0.8296 - val_loss: 1.6085 - val_acc: 0.4927\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.5587 - acc: 0.8352 - val_loss: 1.6347 - val_acc: 0.4894\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.5398 - acc: 0.8414 - val_loss: 1.6441 - val_acc: 0.4881\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.5241 - acc: 0.8490 - val_loss: 1.6562 - val_acc: 0.4864\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.5069 - acc: 0.8558 - val_loss: 1.6535 - val_acc: 0.4839\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 0.4915 - acc: 0.8622 - val_loss: 1.6991 - val_acc: 0.4901\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.4750 - acc: 0.8689 - val_loss: 1.7026 - val_acc: 0.4841\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.4590 - acc: 0.8755 - val_loss: 1.7005 - val_acc: 0.4862\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 0.4440 - acc: 0.8810 - val_loss: 1.7149 - val_acc: 0.4904\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.4289 - acc: 0.8862 - val_loss: 1.7450 - val_acc: 0.4838\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.4125 - acc: 0.8915 - val_loss: 1.7700 - val_acc: 0.4828\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.4005 - acc: 0.8980 - val_loss: 1.7756 - val_acc: 0.4869\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.3865 - acc: 0.9033 - val_loss: 1.7726 - val_acc: 0.4882\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.3702 - acc: 0.9092 - val_loss: 1.7888 - val_acc: 0.4846\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 0.3572 - acc: 0.9147 - val_loss: 1.7968 - val_acc: 0.4830\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 0.3445 - acc: 0.9183 - val_loss: 1.8538 - val_acc: 0.4816\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 0.3335 - acc: 0.9220 - val_loss: 1.8443 - val_acc: 0.4848\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.3180 - acc: 0.9287 - val_loss: 1.8555 - val_acc: 0.4833\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 0.3086 - acc: 0.9307 - val_loss: 1.8797 - val_acc: 0.4828\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 0.2941 - acc: 0.9384 - val_loss: 1.9002 - val_acc: 0.4855\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.2833 - acc: 0.9404 - val_loss: 1.9380 - val_acc: 0.4752\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 0.2718 - acc: 0.9446 - val_loss: 1.9189 - val_acc: 0.4818\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 0.2624 - acc: 0.9475 - val_loss: 1.9625 - val_acc: 0.4813\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.2521 - acc: 0.9508 - val_loss: 1.9867 - val_acc: 0.4757\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.2413 - acc: 0.9546 - val_loss: 1.9745 - val_acc: 0.4830\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "model = build_mlp(input_shape=x_train.shape[1:])\n",
    "model.summary()\n",
    "optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True,\n",
    "          callbacks=[model_ckpt]\n",
    "         )\n",
    "\n",
    "# Collect results\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]\n",
    "\n",
    "# Load back\n",
    "model = keras.models.load_model(\"./tmp.h5\")\n",
    "loss_loadback, acc_loadback = model.evaluate(x_test, y_test)\n",
    "\n",
    "exp_name_tag = \"save_best_only\"\n",
    "results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                                 'valid-loss': valid_loss,\n",
    "                                 'train-acc': train_acc,\n",
    "                                 'valid-acc': valid_acc,\n",
    "                                 'loss_loadback': loss_loadback,\n",
    "                                 'acc_loadback': acc_loadback}\n",
    "\n",
    "\n",
    "model_ckpt = ModelCheckpoint(filepath=\"./tmp_2.h5\", \n",
    "                             monitor=\"val_loss\", \n",
    "                             save_weights_only=True)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True,\n",
    "          callbacks=[model_ckpt]\n",
    "         )\n",
    "\n",
    "# Collect results\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]\n",
    "\n",
    "# Load back\n",
    "#model = keras.models.load_weights(\"./tmp_2.h5\")\n",
    "#loss_loadback, acc_loadback = model.evaluate(x_test, y_test)\n",
    "\n",
    "exp_name_tag = \"save_weights_only\"\n",
    "results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                                 'valid-loss': valid_loss,\n",
    "                                 'train-acc': train_acc,\n",
    "                                 'valid-acc': valid_acc,\n",
    "                                 'loss_loadback': loss_loadback,\n",
    "                                 'acc_loadback': acc_loadback}\n",
    "#model = keras.models.load_weights(\"./tmp_2.h5\")\n",
    "#loss_loadback, acc_loadback = model.evaluate(x_test, y_test)\n",
    "#exp_name_tag = \"save_weights_only\"\n",
    "#results[exp_name_tag] = {'train-loss': train_loss,\n",
    "#                                 'valid-loss': valid_loss,\n",
    "#                                 'train-acc': train_acc,\n",
    "#                                 'valid-acc': valid_acc,\n",
    "#                                 'loss_loadback-acc': loss_loadback,\n",
    "#                                 'acc_loadback-acc': acc_loadback}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'loss_loadback'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7bc7ff135022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train-loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train-loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor_bar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid-loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid-loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor_bar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_loadback'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train-loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor_bar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss_loadback'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\",\"w\",\"c\"]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i%8])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i%8])\n",
    "    plt.hlines(y=results[cond]['loss_loadback'], xmin=0, xmax=len(results[cond]['train-loss']), colors=color_bar[i%8], linestyles='--')\n",
    "plt.title(\"Loss\")\n",
    "plt.ylim([0, 5])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i%8])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i%8])\n",
    "    plt.hlines(y=results[cond]['acc_loadback'], xmin=0, xmax=len(results[cond]['train-loss']), colors=color_bar[i%8], linestyles='--')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 試比較 save_best_only 與否的差異\n",
    "2. 請僅存入將 save_weights_only 設定為 True, 並嘗試 reset ipynb 並將模型與權重重新建回並預測 x_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
