{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例重點\n",
    "* 學習如何在 keras 中撰寫自定義的 loss function\n",
    "* 知道如何在訓練時使用自定義的 loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# 本範例不需使用 GPU, 將 GPU 設定為 \"無\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# 資料前處理 - X 標準化\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# 資料前處理 -Y 轉成 onehot\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "\"\"\"\n",
    "建立神經網路，並加入 BN layer\n",
    "\"\"\"\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "            x = BatchNormalization()(x)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 1024\n",
    "MOMENTUM = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import keras.losses as categorical_crossentropy\n",
    "\n",
    "\"\"\"\n",
    "# 撰寫自定義的 loss function: focal loss (https://blog.csdn.net/u014380165/article/details/77019084)\n",
    "\"\"\"\n",
    "def mix_focal_loss(gamma=2., alpha=4.):\n",
    "    gamma = float(gamma)\n",
    "    alpha = float(alpha)\n",
    "    def mix_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"Focal loss for multi-classification\n",
    "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
    "        \"\"\"\n",
    "        \n",
    "        epsilon = 1e-8\n",
    "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
    "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
    "\n",
    "        model_out = tf.add(y_pred, epsilon)\n",
    "        ce = tf.multiply(y_true, -tf.log(model_out))\n",
    "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
    "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
    "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
    "        return tf.reduce_mean(reduced_fl)*0.3+tf.reduce_mean(ce)*0.7\n",
    "    return mix_focal_loss_fixed\n",
    "\n",
    "def focal_loss(gamma=2., alpha=4.):\n",
    "    gamma = float(gamma)\n",
    "    alpha = float(alpha)\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"Focal loss for multi-classification\n",
    "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
    "        \"\"\"\n",
    "        \n",
    "        epsilon = 1e-8\n",
    "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
    "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
    "\n",
    "        model_out = tf.add(y_pred, epsilon)\n",
    "        ce = tf.multiply(y_true, -tf.log(model_out))\n",
    "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
    "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
    "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
    "        return tf.reduce_mean(reduced_fl)\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 2.2125 - acc: 0.2796 - val_loss: 2.3057 - val_acc: 0.3291\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.6034 - acc: 0.3963 - val_loss: 1.7140 - val_acc: 0.3747\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.4502 - acc: 0.4394 - val_loss: 1.5972 - val_acc: 0.3929\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.3628 - acc: 0.4639 - val_loss: 1.4699 - val_acc: 0.4179\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.2930 - acc: 0.4868 - val_loss: 1.4272 - val_acc: 0.4341\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.2406 - acc: 0.5017 - val_loss: 1.3799 - val_acc: 0.4476\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.1952 - acc: 0.5156 - val_loss: 1.3841 - val_acc: 0.4465\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.1514 - acc: 0.5305 - val_loss: 1.3427 - val_acc: 0.4637\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.1141 - acc: 0.5425 - val_loss: 1.3361 - val_acc: 0.4650\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.0816 - acc: 0.5526 - val_loss: 1.3309 - val_acc: 0.4633\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.0477 - acc: 0.5632 - val_loss: 1.3132 - val_acc: 0.4719\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.0175 - acc: 0.5747 - val_loss: 1.3000 - val_acc: 0.4777\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.9872 - acc: 0.5838 - val_loss: 1.3123 - val_acc: 0.4712\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.9587 - acc: 0.5940 - val_loss: 1.3181 - val_acc: 0.4710\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.9322 - acc: 0.6026 - val_loss: 1.2970 - val_acc: 0.4764\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 0.9030 - acc: 0.6147 - val_loss: 1.2819 - val_acc: 0.4806\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.8798 - acc: 0.6226 - val_loss: 1.2854 - val_acc: 0.4774\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.8537 - acc: 0.6319 - val_loss: 1.2811 - val_acc: 0.4772\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.8296 - acc: 0.6388 - val_loss: 1.2771 - val_acc: 0.4825\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 0.8054 - acc: 0.6474 - val_loss: 1.2835 - val_acc: 0.4810\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.7804 - acc: 0.6588 - val_loss: 1.3057 - val_acc: 0.4767\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.7594 - acc: 0.6642 - val_loss: 1.3067 - val_acc: 0.4810\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.7355 - acc: 0.6764 - val_loss: 1.2990 - val_acc: 0.4781\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.7162 - acc: 0.6801 - val_loss: 1.2903 - val_acc: 0.4884\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.6910 - acc: 0.6921 - val_loss: 1.3166 - val_acc: 0.4802\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.6687 - acc: 0.6985 - val_loss: 1.2941 - val_acc: 0.4862\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.6488 - acc: 0.7077 - val_loss: 1.3218 - val_acc: 0.4809\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.6274 - acc: 0.7179 - val_loss: 1.3219 - val_acc: 0.4808\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.6075 - acc: 0.7247 - val_loss: 1.3204 - val_acc: 0.4853\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.5862 - acc: 0.7325 - val_loss: 1.3354 - val_acc: 0.4839\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.5655 - acc: 0.7408 - val_loss: 1.3360 - val_acc: 0.4835\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.5461 - acc: 0.7500 - val_loss: 1.3440 - val_acc: 0.4837\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.5266 - acc: 0.7593 - val_loss: 1.3515 - val_acc: 0.4840\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.5084 - acc: 0.7654 - val_loss: 1.3789 - val_acc: 0.4782\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.4930 - acc: 0.7748 - val_loss: 1.3719 - val_acc: 0.4835\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.4742 - acc: 0.7818 - val_loss: 1.3949 - val_acc: 0.4731\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 0.4558 - acc: 0.7891 - val_loss: 1.3865 - val_acc: 0.4838\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.4384 - acc: 0.7972 - val_loss: 1.4108 - val_acc: 0.4782\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.4212 - acc: 0.8050 - val_loss: 1.4198 - val_acc: 0.4757\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 0.4066 - acc: 0.8120 - val_loss: 1.4436 - val_acc: 0.4746\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.3893 - acc: 0.8203 - val_loss: 1.4363 - val_acc: 0.4768\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.3766 - acc: 0.8271 - val_loss: 1.4729 - val_acc: 0.4732\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 0.3600 - acc: 0.8364 - val_loss: 1.4797 - val_acc: 0.4784\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3459 - acc: 0.8422 - val_loss: 1.4836 - val_acc: 0.4833\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.3310 - acc: 0.8488 - val_loss: 1.4871 - val_acc: 0.4733\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.3179 - acc: 0.8569 - val_loss: 1.5115 - val_acc: 0.4773\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.3048 - acc: 0.8611 - val_loss: 1.5227 - val_acc: 0.4773\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.2888 - acc: 0.8719 - val_loss: 1.5472 - val_acc: 0.4758\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.2786 - acc: 0.8764 - val_loss: 1.5419 - val_acc: 0.4772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.2666 - acc: 0.8830 - val_loss: 1.5756 - val_acc: 0.4730\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mix_focal_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-39966bb61b4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m                                      'valid-acc': valid_acc}\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmix_focal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m model.fit(x_train, y_train, \n",
      "\u001b[0;31mNameError\u001b[0m: name 'mix_focal_loss' is not defined"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "model = build_mlp(input_shape=x_train.shape[1:])\n",
    "model.summary()\n",
    "optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "\"\"\"\n",
    "# 在 compile 時，使用自定義的 loss function\n",
    "\"\"\"\n",
    "model.compile(loss=focal_loss(), metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True\n",
    "         )\n",
    "\n",
    "# Collect results\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]\n",
    "result_keys=\"focal_loss\"\n",
    "results[result_keys] = {'train-loss': train_loss,\n",
    "                                     'valid-loss': valid_loss,\n",
    "                                     'train-acc': train_acc,\n",
    "                                     'valid-acc': valid_acc}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.2539 - acc: 0.8908 - val_loss: 1.5678 - val_acc: 0.4728\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.2473 - acc: 0.8944 - val_loss: 1.5785 - val_acc: 0.4747\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.2348 - acc: 0.9001 - val_loss: 1.5934 - val_acc: 0.4736\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.2256 - acc: 0.9022 - val_loss: 1.6247 - val_acc: 0.4670\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 0.2161 - acc: 0.9084 - val_loss: 1.6172 - val_acc: 0.4703\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.2067 - acc: 0.9146 - val_loss: 1.6402 - val_acc: 0.4724\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.1979 - acc: 0.9193 - val_loss: 1.6431 - val_acc: 0.4680\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.1890 - acc: 0.9222 - val_loss: 1.6669 - val_acc: 0.4673\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1793 - acc: 0.9275 - val_loss: 1.6718 - val_acc: 0.4669\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.1725 - acc: 0.9314 - val_loss: 1.6808 - val_acc: 0.4704\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.1654 - acc: 0.9365 - val_loss: 1.7190 - val_acc: 0.4664\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.1566 - acc: 0.9417 - val_loss: 1.7146 - val_acc: 0.4710\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.1497 - acc: 0.9449 - val_loss: 1.7098 - val_acc: 0.4744\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 0.1420 - acc: 0.9491 - val_loss: 1.7704 - val_acc: 0.4654\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.1374 - acc: 0.9508 - val_loss: 1.7642 - val_acc: 0.4693\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 0.1308 - acc: 0.9543 - val_loss: 1.7867 - val_acc: 0.4645\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 0.1240 - acc: 0.9588 - val_loss: 1.7722 - val_acc: 0.4687\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.1190 - acc: 0.9606 - val_loss: 1.7917 - val_acc: 0.4692\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 0.1133 - acc: 0.9625 - val_loss: 1.8014 - val_acc: 0.4720\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 0.1086 - acc: 0.9667 - val_loss: 1.8382 - val_acc: 0.4677\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 0.1036 - acc: 0.9681 - val_loss: 1.8718 - val_acc: 0.4599\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.0982 - acc: 0.9708 - val_loss: 1.8455 - val_acc: 0.4664\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.0950 - acc: 0.9728 - val_loss: 1.8696 - val_acc: 0.4676\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 0.0902 - acc: 0.9752 - val_loss: 1.8795 - val_acc: 0.4626\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.0853 - acc: 0.9766 - val_loss: 1.8818 - val_acc: 0.4693\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.0821 - acc: 0.9786 - val_loss: 1.9091 - val_acc: 0.4673\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.0789 - acc: 0.9806 - val_loss: 1.8972 - val_acc: 0.4675\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.0762 - acc: 0.9822 - val_loss: 1.9051 - val_acc: 0.4653\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.0736 - acc: 0.9822 - val_loss: 1.9214 - val_acc: 0.4658\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.0704 - acc: 0.9832 - val_loss: 1.9334 - val_acc: 0.4622\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.0669 - acc: 0.9857 - val_loss: 1.9512 - val_acc: 0.4709\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 0.0648 - acc: 0.9866 - val_loss: 1.9547 - val_acc: 0.4673\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.0613 - acc: 0.9877 - val_loss: 1.9750 - val_acc: 0.4673\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.0592 - acc: 0.9891 - val_loss: 1.9849 - val_acc: 0.4618\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.0569 - acc: 0.9902 - val_loss: 1.9823 - val_acc: 0.4690\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.0552 - acc: 0.9903 - val_loss: 2.0008 - val_acc: 0.4687\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.0530 - acc: 0.9914 - val_loss: 1.9897 - val_acc: 0.4670\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.0508 - acc: 0.9925 - val_loss: 2.0114 - val_acc: 0.4670\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.0489 - acc: 0.9931 - val_loss: 2.0393 - val_acc: 0.4581\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.0471 - acc: 0.9935 - val_loss: 2.0356 - val_acc: 0.4667\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 0.0457 - acc: 0.9936 - val_loss: 2.0772 - val_acc: 0.4644\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.0436 - acc: 0.9947 - val_loss: 2.0585 - val_acc: 0.4618\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.0425 - acc: 0.9950 - val_loss: 2.0729 - val_acc: 0.4674\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.0414 - acc: 0.9951 - val_loss: 2.0712 - val_acc: 0.4666\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.0403 - acc: 0.9955 - val_loss: 2.0662 - val_acc: 0.4658\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.0383 - acc: 0.9962 - val_loss: 2.0861 - val_acc: 0.4664\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.0371 - acc: 0.9966 - val_loss: 2.0981 - val_acc: 0.4655\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 0.0361 - acc: 0.9967 - val_loss: 2.1042 - val_acc: 0.4665\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.0357 - acc: 0.9962 - val_loss: 2.1070 - val_acc: 0.4622\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.0349 - acc: 0.9969 - val_loss: 2.1325 - val_acc: 0.4656\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=mix_focal_loss(), metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True\n",
    "         )\n",
    "\n",
    "# Collect results\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]\n",
    "result_keys=\"mix_focal_loss\"\n",
    "results[result_keys] = {'train-loss': train_loss,\n",
    "                                     'valid-loss': valid_loss,\n",
    "                                     'train-acc': train_acc,\n",
    "                                     'valid-acc': valid_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\",\"w\",\"c\"]\n",
    "\n",
    "print(results.keys())\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i%8])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i%8])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i%8])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i%8])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請自行定義一個 loss function, 為 0.3 * focal loss + 0.7 cross-entropy，訓練並比較結果\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
